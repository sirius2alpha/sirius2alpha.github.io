<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>hadoop部署 | Sirius' Blog</title>
<meta name=keywords content="hadoop,hive,hdfs,分布式,数据库原理,deployment"><meta name=description content="这篇文章记录了在三台云服务器上部署hadoop的过程"><meta name=author content="sirius1y"><link rel=canonical href=https://sirius1y.top/posts/notes/deployment/deploy-hadoophive/><link crossorigin=anonymous href=/assets/css/stylesheet.3551607c8eb1ef998f0b6c81d22f9f03dd2c3b8ecaf983e42c023e8d41e39f66.css integrity="sha256-NVFgfI6x75mPC2yB0i+fA90sO47K+YPkLAI+jUHjn2Y=" rel="preload stylesheet" as=style><link rel=icon href=https://sirius1y.top/images/icon.png><link rel=icon type=image/png sizes=16x16 href=https://sirius1y.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://sirius1y.top/favicon-32x32.png><link rel=apple-touch-icon href=https://sirius1y.top/apple-touch-icon.png><link rel=mask-icon href=https://sirius1y.top/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://sirius1y.top/posts/notes/deployment/deploy-hadoophive/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="hadoop部署"><meta property="og:description" content="这篇文章记录了在三台云服务器上部署hadoop的过程"><meta property="og:type" content="article"><meta property="og:url" content="https://sirius1y.top/posts/notes/deployment/deploy-hadoophive/"><meta property="og:image" content="https://sirius1y.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-12-14T00:00:00+00:00"><meta property="article:modified_time" content="2023-12-14T00:00:00+00:00"><meta property="og:site_name" content="Sirius' Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://sirius1y.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="hadoop部署"><meta name=twitter:description content="这篇文章记录了在三台云服务器上部署hadoop的过程"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://sirius1y.top/posts/"},{"@type":"ListItem","position":2,"name":"hadoop部署","item":"https://sirius1y.top/posts/notes/deployment/deploy-hadoophive/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"hadoop部署","name":"hadoop部署","description":"这篇文章记录了在三台云服务器上部署hadoop的过程","keywords":["hadoop","hive","hdfs","分布式","数据库原理","deployment"],"articleBody":"生成密钥并实现自我登录 sudo apt-get install vim sudo apt-get install openssh-server cd .ssh ssh-keygen -t rsa -C \"sirius1y@outlook.com\" cat id_rsa.pub \u003e authorized_keys 安装java sudo apt-get install openjdk-8-jre openjdk-8-jdk 检查java是否安装完成 java -version 下载hadoop 网站：https://archive.apache.org/dist/hadoop/common/hadoop-2.7.0/\nwget https://archive.apache.org/dist/hadoop/common/hadoop-2.7.0/hadoop-2.7.0.tar.gz # 解压 sudo tar -zxf hadoop-2.7.0.tar.gz -C /usr/local 修改所有权：\ncd /usr/local sudo mv hadoop-2.7.0/ hadoop sudo chown -R ubuntu ./hadoop 设置JAVA_HOME环境变量 sudo vim ~/.bashrc # 把下面内容添加到末尾 export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 删除~/.ssh/kown_hosts\n创建镜像之后新建示例\n发现能够存在hadoop\n—————–创建两台镜像\n取机器的昵称 sudo vim /etc/hostname添加自己的名字\nsudo vim /etc/hosts，这里都是使用的内网IP地址\n重启之后，每台机器的名字都变了\n并且可以通过直接ssh master,ssh slave01的方式直接访问；\n修改master和slaves配置文件 cd /usr/local/hadoop/etc/hadoop/ 修改这些配置文件\n配置文件详情：\nhttps://www.aidac-shu.com/courses/的reference部分\n# slaves slave01 slave02 # core-site.xml hadoop.tmp.dir /usr/local/hadoop/tmp Abase for other temporary directories. fs.defaultFS hdfs://master:9000 # hdfs-site.xml dfs.replication 3 # mapred-site.xml mapreduce.framework.name yarn # yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle yarn.resourcemanager.hostname master 用jps检查java进程执行情况\n启动hadoop /usr/local/hadoop/bin/hdfs namenode -format 在这之后会得到一大串的输出，最后会出现两个0,表示成功执行：\n/usr/local/hadoop/sbin/start-all.sh 刚开始启用这条命令的时候会出现JAVA_HOME没有设置的情况，但是我已经在~/.bashrc中设置了(尝试过在/etc/bash.bashrc也不行)\n原因很有可能是环境变量并没有作用到/usr/local/hadoop中。\n然后我在/usr/local/hadoop/etc/hadoop/hadoop-env.sh中设置了export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64之后（在master和两台slave上都设置）了，在启用命令sbin/start-all.sh就能成功执行。\nHDFS使用 添加HADOOP环境变量 可以把HADOOP的位置/usr/local/hadoop/添加到环境变量中，就可以直接访问hadoop和hdfs了\nexport HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin 文件操作 在slave01上把文件放入到/中: hdfs dfs -put etc/hadoop/*.xml /\n使用命令hdfs dfs -ls /会列出文件系统/下的所有文件\n在这里演示，在文件系统中先创建一个目录/user/input/，再把文件try.sh放入其中，再进行查看\n需要注意的是，需要在目录创建成功之后再进行put操作，否则只会创建目录，但是不会把文件放入其中的操作。(好奇怪)\n另外，在任何一个结点上创建的文件都会同步到其他几台机器上。\n配置HIVE 下载hive 在master上的主目录上，运行\nwget https://dlcdn.apache.org/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz 解压到主目录下 ubuntu@master:~$ tar -zxvf apache-hive-1.2.2-bin.tar.gz -C ~ 更改名字+更改所有权 # 改名 mv ubuntu@master:~$ ls apache-hive-1.2.2-bin apache-hive-1.2.2-bin.tar.gz hadoop-2.7.0.tar.gz ubuntu@master:~$ mv apache-hive-1.2.2-bin hive ubuntu@master:~$ ls apache-hive-1.2.2-bin.tar.gz hadoop-2.7.0.tar.gz hive # 更改所有权 chown ubuntu@master:~$ sudo chown -R ubuntu ./hive 把hive添加到环境变量中 # ~/.bashrc export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin export HIVE_HOME=/home/ubuntu/hive/ export PATH=$PATH:$HIVE_HOME/bin 完成之后更新 source ~/.bashrc\n运行hive # HiveSQL # 创建数据库 CREATE DATABASE one; # 查看数据库 SHOW DATABASES; # 切换数据库 USE database_name; # 查看该数据库下面的所有表 SHOW TABLES; # 新建表 CREATE TABLE employees( id INT, name STRING, department STRING ); # 插入数据 INSERT INTO TABLE employees (id, name, department) VALUES (1, 'Alice', 'IT'); INSERT INTO TABLE employees (id, name, department) VALUES (2, 'Bob', 'HR'); INSERT INTO TABLE employees (id, name, department) VALUES (3, 'Charlie', 'Finance'); # 查询操作 SELECT * FROM employees; SELECT * FROM employees WHERE department='IT'; 插入过程中的一些截图，他这个插入还比较麻烦：\n分为了三个部分进行执行。\n查询展示：\n","wordCount":"307","inLanguage":"en","image":"https://sirius1y.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2023-12-14T00:00:00Z","dateModified":"2023-12-14T00:00:00Z","author":{"@type":"Person","name":"sirius1y"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://sirius1y.top/posts/notes/deployment/deploy-hadoophive/"},"publisher":{"@type":"Organization","name":"Sirius' Blog","logo":{"@type":"ImageObject","url":"https://sirius1y.top/images/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://sirius1y.top/ accesskey=h title="Home (Alt + H)"><img src=https://sirius1y.top/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://sirius1y.top/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://sirius1y.top/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://sirius1y.top/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://sirius1y.top/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://sirius1y.top/>Home</a>&nbsp;»&nbsp;<a href=https://sirius1y.top/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">hadoop部署</h1><div class=post-description>这篇文章记录了在三台云服务器上部署hadoop的过程</div><div class=post-meta><span title='2023-12-14 00:00:00 +0000 UTC'>December 14, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;307 words&nbsp;·&nbsp;sirius1y</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><ul><li><a href=#%e7%94%9f%e6%88%90%e5%af%86%e9%92%a5%e5%b9%b6%e5%ae%9e%e7%8e%b0%e8%87%aa%e6%88%91%e7%99%bb%e5%bd%95 aria-label=生成密钥并实现自我登录>生成密钥并实现自我登录</a></li><li><a href=#%e5%ae%89%e8%a3%85java aria-label=安装java>安装java</a><ul><li><a href=#%e6%a3%80%e6%9f%a5java%e6%98%af%e5%90%a6%e5%ae%89%e8%a3%85%e5%ae%8c%e6%88%90 aria-label=检查java是否安装完成>检查java是否安装完成</a></li></ul></li><li><a href=#%e4%b8%8b%e8%bd%bdhadoop aria-label=下载hadoop>下载hadoop</a><ul><li><a href=#%e8%ae%be%e7%bd%aejava_home%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f aria-label=设置JAVA_HOME环境变量>设置JAVA_HOME环境变量</a></li><li><a href=#%e5%8f%96%e6%9c%ba%e5%99%a8%e7%9a%84%e6%98%b5%e7%a7%b0 aria-label=取机器的昵称>取机器的昵称</a></li><li><a href=#%e4%bf%ae%e6%94%b9master%e5%92%8cslaves%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label=修改master和slaves配置文件>修改master和slaves配置文件</a></li></ul></li><li><a href=#%e5%90%af%e5%8a%a8hadoop aria-label=启动hadoop>启动hadoop</a></li><li><a href=#hdfs%e4%bd%bf%e7%94%a8 aria-label=HDFS使用>HDFS使用</a><ul><li><a href=#%e6%b7%bb%e5%8a%a0hadoop%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f aria-label=添加HADOOP环境变量>添加HADOOP环境变量</a></li><li><a href=#%e6%96%87%e4%bb%b6%e6%93%8d%e4%bd%9c aria-label=文件操作>文件操作</a></li></ul></li></ul><li><a href=#%e9%85%8d%e7%bd%aehive aria-label=配置HIVE>配置HIVE</a><ul><li><a href=#%e4%b8%8b%e8%bd%bdhive aria-label=下载hive>下载hive</a><ul><li><a href=#%e8%a7%a3%e5%8e%8b%e5%88%b0%e4%b8%bb%e7%9b%ae%e5%bd%95%e4%b8%8b aria-label=解压到主目录下>解压到主目录下</a></li><li><a href=#%e6%9b%b4%e6%94%b9%e5%90%8d%e5%ad%97%e6%9b%b4%e6%94%b9%e6%89%80%e6%9c%89%e6%9d%83 aria-label=更改名字+更改所有权>更改名字+更改所有权</a></li><li><a href=#%e6%8a%8ahive%e6%b7%bb%e5%8a%a0%e5%88%b0%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f%e4%b8%ad aria-label=把hive添加到环境变量中>把hive添加到环境变量中</a></li></ul></li><li><a href=#%e8%bf%90%e8%a1%8chive aria-label=运行hive>运行hive</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h3 id=生成密钥并实现自我登录>生成密钥并实现自我登录<a hidden class=anchor aria-hidden=true href=#生成密钥并实现自我登录>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt-get install vim
</span></span><span class=line><span class=cl>sudo apt-get install openssh-server
</span></span><span class=line><span class=cl><span class=nb>cd</span> .ssh
</span></span><span class=line><span class=cl>ssh-keygen -t rsa -C <span class=s2>&#34;sirius1y@outlook.com&#34;</span>
</span></span><span class=line><span class=cl>cat id_rsa.pub &gt; authorized_keys
</span></span></code></pre></div><p><img loading=lazy src=https://s2.loli.net/2023/12/14/SeFMJrOcvl8wy4V.png alt=图片1></p><h3 id=安装java>安装java<a hidden class=anchor aria-hidden=true href=#安装java>#</a></h3><pre tabindex=0><code>sudo apt-get install openjdk-8-jre openjdk-8-jdk
</code></pre><h4 id=检查java是否安装完成>检查java是否安装完成<a hidden class=anchor aria-hidden=true href=#检查java是否安装完成>#</a></h4><pre tabindex=0><code>java -version
</code></pre><h3 id=下载hadoop>下载hadoop<a hidden class=anchor aria-hidden=true href=#下载hadoop>#</a></h3><p>网站：https://archive.apache.org/dist/hadoop/common/hadoop-2.7.0/</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget https://archive.apache.org/dist/hadoop/common/hadoop-2.7.0/hadoop-2.7.0.tar.gz
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 解压</span>
</span></span><span class=line><span class=cl>sudo tar -zxf hadoop-2.7.0.tar.gz -C /usr/local
</span></span></code></pre></div><p>修改所有权：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> /usr/local
</span></span><span class=line><span class=cl>sudo mv hadoop-2.7.0/ hadoop
</span></span><span class=line><span class=cl>sudo chown -R ubuntu ./hadoop
</span></span></code></pre></div><p><img loading=lazy src=https://s2.loli.net/2023/12/14/8kF1PyrnROc9ZMg.png alt=图片2></p><h4 id=设置java_home环境变量>设置JAVA_HOME环境变量<a hidden class=anchor aria-hidden=true href=#设置java_home环境变量>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo vim ~/.bashrc
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 把下面内容添加到末尾</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>JAVA_HOME</span><span class=o>=</span>/usr/lib/jvm/java-8-openjdk-amd64
</span></span></code></pre></div><p><img loading=lazy src=https://s2.loli.net/2023/12/14/ewuXvmhE85iWlHR.png alt=图片3></p><p>删除~/.ssh/kown_hosts</p><p>创建镜像之后新建示例</p><p>发现能够存在hadoop</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/59vYaNkGD7JAWlb.png alt=图片4></p><p>&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;创建两台镜像</p><h4 id=取机器的昵称>取机器的昵称<a hidden class=anchor aria-hidden=true href=#取机器的昵称>#</a></h4><p><code>sudo vim /etc/hostname</code>添加自己的名字</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/SyXokEAMwWRjZ8i.png alt=图片5></p><p><code>sudo vim /etc/hosts</code>，这里都是使用的<strong>内网IP地址</strong></p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/av9TStrykmKPRVx.png alt=图片6></p><p>重启之后，每台机器的名字都变了</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/7CIDMe8AirYfckL.png alt=图片7></p><p>并且可以通过直接<code>ssh master</code>,<code>ssh slave01</code>的方式直接访问；</p><h4 id=修改master和slaves配置文件>修改master和slaves配置文件<a hidden class=anchor aria-hidden=true href=#修改master和slaves配置文件>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> /usr/local/hadoop/etc/hadoop/
</span></span></code></pre></div><p>修改这些配置文件</p><p>配置文件详情：</p><p><a href=https://www.aidac-shu.com/courses/>https://www.aidac-shu.com/courses/</a>的reference部分</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/W4g5zPfqAsdHZEB.png alt=图片8></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl># slaves
</span></span><span class=line><span class=cl>slave01
</span></span><span class=line><span class=cl>slave02
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl># core-site.xml
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;name&gt;</span>hadoop.tmp.dir<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;value&gt;</span>/usr/local/hadoop/tmp<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;description&gt;</span>Abase for other temporary directories.<span class=nt>&lt;/description&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;name&gt;</span>fs.defaultFS<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;value&gt;</span>hdfs://master:9000<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl># hdfs-site.xml
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;name&gt;</span>dfs.replication<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;value&gt;</span>3<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl># mapred-site.xml
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;name&gt;</span>mapreduce.framework.name<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;value&gt;</span>yarn<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl># yarn-site.xml
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl><span class=c>&lt;!--  Site specific YARN configuration properties  --&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;name&gt;</span>yarn.nodemanager.aux-services<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;value&gt;</span>mapreduce_shuffle<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;name&gt;</span>yarn.resourcemanager.hostname<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;value&gt;</span>master<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><p><img loading=lazy src=https://s2.loli.net/2023/12/14/mda3cD5YObRyzX4.png alt=图片8></p><p>用<code>jps</code>检查java进程执行情况</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/34hyKYJlxvZgcr1.png alt=图片10></p><h3 id=启动hadoop>启动hadoop<a hidden class=anchor aria-hidden=true href=#启动hadoop>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>/usr/local/hadoop/bin/hdfs namenode -format
</span></span></code></pre></div><p>在这之后会得到一大串的输出，最后会出现两个0,表示成功执行：</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/q5n6Jt3alNS4DE8.png alt=图片11></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>/usr/local/hadoop/sbin/start-all.sh
</span></span></code></pre></div><p><img loading=lazy src=https://s2.loli.net/2023/12/14/Tt38nRZzDPgHmC1.png alt=图片12></p><p>刚开始启用这条命令的时候会出现JAVA_HOME没有设置的情况，但是我已经在<code>~/.bashrc</code>中设置了(尝试过在/etc/bash.bashrc也不行)</p><p>原因很有可能是环境变量并没有作用到<code>/usr/local/hadoop</code>中。</p><p>然后我在<code>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</code>中设置了<code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64</code>之后（在master和两台slave上都设置）了，在启用命令<code>sbin/start-all.sh</code>就能成功执行。</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/Dl2zAMHpaVTNYrI.png alt=图片13></p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/ix2T4ENXC3DUzFO.png alt=图片14></p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/vigGIfO1pwAqurc.png alt=图片15></p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/rkMmTQ9N6OSJZqc.png alt=图片16></p><h3 id=hdfs使用>HDFS使用<a hidden class=anchor aria-hidden=true href=#hdfs使用>#</a></h3><h4 id=添加hadoop环境变量>添加HADOOP环境变量<a hidden class=anchor aria-hidden=true href=#添加hadoop环境变量>#</a></h4><p>可以把HADOOP的位置/usr/local/hadoop/添加到环境变量中，就可以直接访问hadoop和hdfs了</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>HADOOP_HOME</span><span class=o>=</span>/usr/local/hadoop
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>PATH</span><span class=o>=</span><span class=nv>$PATH</span>:<span class=nv>$HADOOP_HOME</span>/bin
</span></span></code></pre></div><p><img loading=lazy src=https://s2.loli.net/2023/12/14/SlzMeRJGtrKQ84m.png alt=图片17></p><h4 id=文件操作>文件操作<a hidden class=anchor aria-hidden=true href=#文件操作>#</a></h4><p>在slave01上把文件放入到/中: hdfs dfs -put etc/hadoop/*.xml /</p><p>使用命令<code>hdfs dfs -ls /</code>会列出文件系统/下的所有文件</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/bdHCAXDs5vZpQny.png alt=图片18></p><p>在这里演示，在文件系统中先创建一个目录/user/input/，再把文件try.sh放入其中，再进行查看</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/UC4QNkH5M6uvqgV.png alt=图片19></p><p>需要注意的是，需要在目录创建成功之后再进行put操作，否则只会创建目录，但是不会把文件放入其中的操作。(好奇怪)</p><p>另外，在任何一个结点上创建的文件都会同步到其他几台机器上。</p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/DdaGAFvLsT81RNW.png alt=图片20></p><p><img loading=lazy src=https://s2.loli.net/2023/12/14/u15mt6iG9jW3YCA.png alt=图片21></p><h2 id=配置hive>配置HIVE<a hidden class=anchor aria-hidden=true href=#配置hive>#</a></h2><h3 id=下载hive>下载hive<a hidden class=anchor aria-hidden=true href=#下载hive>#</a></h3><p>在master上的主目录上，运行</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget https://dlcdn.apache.org/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz
</span></span></code></pre></div><h4 id=解压到主目录下>解压到主目录下<a hidden class=anchor aria-hidden=true href=#解压到主目录下>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ubuntu@master:~$ tar -zxvf apache-hive-1.2.2-bin.tar.gz -C ~
</span></span></code></pre></div><h4 id=更改名字更改所有权>更改名字+更改所有权<a hidden class=anchor aria-hidden=true href=#更改名字更改所有权>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 改名 mv</span>
</span></span><span class=line><span class=cl>ubuntu@master:~$ ls
</span></span><span class=line><span class=cl>apache-hive-1.2.2-bin  apache-hive-1.2.2-bin.tar.gz  hadoop-2.7.0.tar.gz
</span></span><span class=line><span class=cl>ubuntu@master:~$ mv apache-hive-1.2.2-bin hive
</span></span><span class=line><span class=cl>ubuntu@master:~$ ls
</span></span><span class=line><span class=cl>apache-hive-1.2.2-bin.tar.gz  hadoop-2.7.0.tar.gz  hive
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 更改所有权 chown</span>
</span></span><span class=line><span class=cl>ubuntu@master:~$ sudo chown -R ubuntu ./hive
</span></span></code></pre></div><h4 id=把hive添加到环境变量中>把hive添加到环境变量中<a hidden class=anchor aria-hidden=true href=#把hive添加到环境变量中>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># ~/.bashrc</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>JAVA_HOME</span><span class=o>=</span>/usr/lib/jvm/java-8-openjdk-amd64
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>HADOOP_HOME</span><span class=o>=</span>/usr/local/hadoop
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>PATH</span><span class=o>=</span><span class=nv>$PATH</span>:<span class=nv>$HADOOP_HOME</span>/bin
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>HIVE_HOME</span><span class=o>=</span>/home/ubuntu/hive/
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>PATH</span><span class=o>=</span><span class=nv>$PATH</span>:<span class=nv>$HIVE_HOME</span>/bin
</span></span></code></pre></div><p>完成之后更新 <code>source ~/.bashrc</code></p><h3 id=运行hive>运行hive<a hidden class=anchor aria-hidden=true href=#运行hive>#</a></h3><p><img loading=lazy src=https://s2.loli.net/2023/12/21/hO4TgCJRsAkpaZ8.png alt=image-20231221193739573></p><pre tabindex=0><code class=language-hive data-lang=hive># HiveSQL
# 创建数据库
CREATE DATABASE one;

# 查看数据库
SHOW DATABASES;

# 切换数据库
USE database_name;

# 查看该数据库下面的所有表
SHOW TABLES;

# 新建表
CREATE TABLE employees(
	id INT,
    name STRING,
    department STRING
);

# 插入数据
INSERT INTO TABLE employees (id, name, department) VALUES (1, &#39;Alice&#39;, &#39;IT&#39;);
INSERT INTO TABLE employees (id, name, department) VALUES (2, &#39;Bob&#39;, &#39;HR&#39;);
INSERT INTO TABLE employees (id, name, department) VALUES (3, &#39;Charlie&#39;, &#39;Finance&#39;);


# 查询操作
SELECT * FROM employees;
SELECT * FROM employees WHERE department=&#39;IT&#39;;
</code></pre><p>插入过程中的一些截图，他这个插入还比较麻烦：</p><p>分为了三个部分进行执行。</p><p><img loading=lazy src=https://s2.loli.net/2023/12/21/qVaWYTcKb47xrSv.png alt=image-20231221203144988></p><p><img loading=lazy src=https://s2.loli.net/2023/12/21/tSlPHsop1Qmg8BA.png alt=image-20231221203202258></p><p>查询展示：</p><p><img loading=lazy src=https://s2.loli.net/2023/12/21/utHKCweYW8czgFn.png alt=image-20231221203034689></p><p><img loading=lazy src=https://s2.loli.net/2023/12/21/QmtkgaJU2D7YoF3.png alt=image-20231221202956806></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://sirius1y.top/tags/hadoop/>Hadoop</a></li><li><a href=https://sirius1y.top/tags/hive/>Hive</a></li><li><a href=https://sirius1y.top/tags/hdfs/>Hdfs</a></li><li><a href=https://sirius1y.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/>分布式</a></li><li><a href=https://sirius1y.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/>数据库原理</a></li><li><a href=https://sirius1y.top/tags/deployment/>Deployment</a></li></ul><nav class=paginav><a class=prev href=https://sirius1y.top/posts/notes/deployment/deploy-dockerk8s/><span class=title>« Prev</span><br><span>Docker和K8S部署</span>
</a><a class=next href=https://sirius1y.top/posts/notes/deployment/deploy-mysql-oncloud/><span class=title>Next »</span><br><span>在云服务器上部署mysql</span></a></nav></footer><script>function createGiscusScript(e){const t=document.createElement("script");Object.entries(e).forEach(([e,n])=>t.setAttribute(e,n)),document.querySelector("article").appendChild(t);const n=document.querySelector('label[for="switch_default"]');n&&n.addEventListener("click",function(){const e=document.body.classList.contains("dark")?"transparent_dark":"light";t.setAttribute("data-theme",e),sendMessage({setConfig:{theme:e}})})}function sendMessage(e){const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")}document.addEventListener("DOMContentLoaded",function(){const e={src:"https://giscus.app/client.js","data-repo":"yunyit/yunyit.github.io","data-repo-id":"R_kgDOKqkPYw","data-category":"Comments","data-category-id":"DIC_kwDOKqkPY84CceDi","data-mapping":"url","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-lang":"en",crossorigin:"anonymous",async:""};e["data-theme"]=document.body.classList.contains("dark")?"transparent_dark":"light",createGiscusScript(e);const t=new MutationObserver(()=>{const e=document.body.classList.contains("dark")?"transparent_dark":"light";sendMessage({setConfig:{theme:e}})});t.observe(document.body,{attributes:!0,attributeFilter:["class"]})})</script></article></main><footer class=footer><span><a href=https://us.umami.is/websites/5e6ac0c1-e2b2-4d0f-9542-b79ac2cf89c4 rel="noopener noreferrer" target=_blank>Analysis</a>
</span>|
<script defer src=https://cloud.umami.is/script.js data-website-id=5e6ac0c1-e2b2-4d0f-9542-b79ac2cf89c4></script><span><a href=https://beian.miit.gov.cn/ target=_blank>渝ICP备2024018631号</a>
</span>|
<span>&copy; 2025 <a href=https://sirius1y.top/>Sirius' Blog</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>